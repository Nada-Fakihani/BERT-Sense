{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Deep Learning using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intermediate-level knowledge of Python 3 (NumPy and Pandas preferably, but not required)\n",
    "- Exposure to PyTorch usage\n",
    "- Basic understanding of Deep Learning and Language Models (BERT specifically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Introduction ((Expliquer la différence entre BERT/CamemBERT et Tfidf))\n",
    "\n",
    "**Task 2**: Analyse exploratoire et prétraitement des données\n",
    "\n",
    "**Task 3**: Training/Validation Split\n",
    "\n",
    "**Task 4**: Chargement du Tokenizer et encodage de nos données\n",
    "\n",
    "**Task 5**: Entrainer un modèle\n",
    "\n",
    "**Task 6**: Classification des documents à l'aide de la régression logistique multinomiale\n",
    "\n",
    "**Task 7**: Evaluation sur la base de validation\n",
    "\n",
    "**Task 8**: Tester le Random Forest, SVM, Xgboost, Light GBM, Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Introduction (Expliquer la différence entre BERT/CamemBERT et Tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is BERT\n",
    "\n",
    "BERT is a large-scale transformer-based Language Model that can be finetuned for a variety of tasks.\n",
    "\n",
    "For more information, the original paper can be found [here](https://arxiv.org/abs/1810.04805). \n",
    "\n",
    "[HuggingFace documentation](https://huggingface.co/transformers/model_doc/bert.html)\n",
    "\n",
    "[Bert documentation](https://characters.fandom.com/wiki/Bert_(Sesame_Street) ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"BERT_diagrams.pdf\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Analyse exploratoire et prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the SMILE Twitter dataset.\n",
    "\n",
    "_Wang, Bo; Tsakalidis, Adam; Liakata, Maria; Zubiaga, Arkaitz; Procter, Rob; Jensen, Eric (2016): SMILE Twitter Emotion dataset. figshare. Dataset. https://doi.org/10.6084/m9.figshare.3187909.v2_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'smile-annotations-final.csv',\n",
    "    names=['id', 'text', 'category']\n",
    ")\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611857364396965889</th>\n",
       "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
       "      <td>nocode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text category\n",
       "id                                                                            \n",
       "611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
       "614877582664835073  @Sofabsports thank you for following me back. ...    happy\n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...    happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "nocode               1572\n",
       "happy                1137\n",
       "not-relevant          214\n",
       "angry                  57\n",
       "surprise               35\n",
       "sad                    32\n",
       "happy|surprise         11\n",
       "happy|sad               9\n",
       "disgust|angry           7\n",
       "disgust                 6\n",
       "sad|disgust             2\n",
       "sad|angry               2\n",
       "sad|disgust|angry       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].iloc[0]  # Regarder le premier commentaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enlever toutes les lignes contenant le caractere |\n",
    "df = df[~df['category'].str.contains('\\|')]\n",
    "# (synonyme de double sentiment exprime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.str` permet d'appliquer des fonctions sur les strings d'une colonne.\n",
    "\n",
    "Ici, on applique la méthode `.contains()` pour vérifier si la colonne `category` contient des caractères spéciaux. Ensuite on peut inverser le résultat avec `~` pour avoir les lignes qui ne contiennent pas de caractères spéciaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enlever les lignes contenant la modalite nocode\n",
    "df = df[df[\"category\"] != 'nocode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "happy           1137\n",
       "not-relevant     214\n",
       "angry             57\n",
       "surprise          35\n",
       "sad               32\n",
       "disgust            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "possible_labels = df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, la méthode `.unique()` permet de retourner les valeurs uniques d'une colonne.\n",
    "\n",
    "On utilise ensuite une boucle pour labelliser chacune des catégories.\n",
    "\n",
    "Un remplacement possible avec une dict comprehension :\n",
    "\n",
    "```python\n",
    "label_dict = {val:idx for idx, val in enumerate(df.category.unique())}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'happy': 0,\n",
       " 'not-relevant': 1,\n",
       " 'angry': 2,\n",
       " 'disgust': 3,\n",
       " 'sad': 4,\n",
       " 'surprise': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611570404268883969</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614499696015503361</th>\n",
       "      <td>Lucky @FitzMuseum_UK! Good luck @MirandaStearn...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613601881441570816</th>\n",
       "      <td>Yr 9 art students are off to the @britishmuseu...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613696526297210880</th>\n",
       "      <td>@RAMMuseum Please vote for us as @sainsbury #s...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610746718641102848</th>\n",
       "      <td>#AskTheGallery Have you got plans to privatise...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612648200588038144</th>\n",
       "      <td>@BarbyWT @britishmuseum so beautiful</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "id                                                                      \n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n",
       "614499696015503361  Lucky @FitzMuseum_UK! Good luck @MirandaStearn...   \n",
       "613601881441570816  Yr 9 art students are off to the @britishmuseu...   \n",
       "613696526297210880  @RAMMuseum Please vote for us as @sainsbury #s...   \n",
       "610746718641102848  #AskTheGallery Have you got plans to privatise...   \n",
       "612648200588038144               @BarbyWT @britishmuseum so beautiful   \n",
       "\n",
       "                        category  label  \n",
       "id                                       \n",
       "614484565059596288         happy      0  \n",
       "614746522043973632         happy      0  \n",
       "614877582664835073         happy      0  \n",
       "611932373039644672         happy      0  \n",
       "611570404268883969         happy      0  \n",
       "614499696015503361         happy      0  \n",
       "613601881441570816         happy      0  \n",
       "613696526297210880  not-relevant      1  \n",
       "610746718641102848  not-relevant      1  \n",
       "612648200588038144         happy      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['category'].map(label_dict)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.map()` permet de passer chacune des valeurs d'une colonne dans un dictionnaire pour les remplacer par une autre valeur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, X_y_val = train_test_split(\n",
    "    df.index.values,\n",
    "    df.label.values,\n",
    "    test_size=0.15,\n",
    "    random_state=17,  # Pour la reproductibilite des analyses/resultats\n",
    "    stratify=df.label.values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'argument important ici est `stratify`. Il permet de s'assurer que les proportions de chaque classe sont respectées dans les deux jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creation de la base d'apprentissage et de test\n",
    "df['data_type'] = ['not_set']*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disgust</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sad</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text\n",
       "category     label data_type      \n",
       "angry        2     train        48\n",
       "                   val           9\n",
       "disgust      3     train         5\n",
       "                   val           1\n",
       "happy        0     train       966\n",
       "                   val         171\n",
       "not-relevant 1     train       182\n",
       "                   val          32\n",
       "sad          4     train        27\n",
       "                   val           5\n",
       "surprise     5     train        30\n",
       "                   val           5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['category', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On s'assure que les proportions sont respectées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Chargement du Tokenizer et encodage de nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers as ppb\n",
    "\n",
    "camembert, tokenizer, weights = (\n",
    "    ppb.CamembertModel, ppb.CamembertTokenizer, 'camembert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72513e18eb1f4f47ba2b01342d85b579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\zamax\\.cache\\huggingface\\hub\\models--camembert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517fed9dee014de1befd631f5937f351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037d1369f8ef41ddb70c16d612662325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cfdc6068484edcb66f995568ed0234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer.from_pretrained(weights)\n",
    "model = camembert.from_pretrained(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_app = df[df['data_type'] == 'train']\n",
    "df_test = df[df['data_type'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611570404268883969</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "id                                                                      \n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n",
       "\n",
       "                   category  label data_type  \n",
       "id                                            \n",
       "614484565059596288    happy      0     train  \n",
       "614746522043973632    happy      0     train  \n",
       "614877582664835073    happy      0     train  \n",
       "611932373039644672    happy      0     train  \n",
       "611570404268883969    happy      0     train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_app.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  97\n",
      "Max sentence length:  73\n"
     ]
    }
   ],
   "source": [
    "# see if there are length > 512\n",
    "max_len_app = 0\n",
    "for i, sent in enumerate(df_app['text']):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids_app = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    if len(input_ids_app) > 512:\n",
    "        print(\"annoying review at\", i, \"with length\",\n",
    "              len(input_ids_app))\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_app = max(max_len_app, len(input_ids_app))\n",
    "\n",
    "print('Max sentence length: ', max_len_app)\n",
    "\n",
    "# see if there are length > 512\n",
    "max_len_test = 0\n",
    "for i, sent in enumerate(df_test['text']):\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids_test = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    if len(input_ids_test) > 512:\n",
    "        print(\"annoying review at\", i, \"with length\",\n",
    "              len(input_ids_test))\n",
    "    # Update the maximum sentence length.\n",
    "    max_len_test = max(max_len_test, len(input_ids_test))\n",
    "\n",
    "print('Max sentence length: ', max_len_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici le code n'affiche rien d'autre que les longueurs de texte maximale ce qui veut dire que tous les textes sont plus courts que 512.\n",
    "\n",
    "On peut donc continuer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 97)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_app = df_app['text'].apply(\n",
    "    (lambda x: tokenizer.encode(str(x), add_special_tokens=True)))\n",
    "max_len_app = 0\n",
    "for i in tokenized_app.values:\n",
    "    if len(i) > max_len_app:\n",
    "        max_len_app = len(i)\n",
    "\n",
    "padded_app = np.array([i + [0]*(max_len_app-len(i))\n",
    "                      for i in tokenized_app.values])\n",
    "np.array(padded_app).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit ensuite une liste encodée pour chaque texte. Logiquement, `.shape` retourne le nombre de textes et la longueur maximale de ces textes, ici 92."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 73)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_test = df_test['text'].apply(\n",
    "    (lambda x: tokenizer.encode(str(x), add_special_tokens=True)))\n",
    "max_len_test = 0\n",
    "for i in tokenized_test.values:\n",
    "    if len(i) > max_len_test:\n",
    "        max_len_test = len(i)\n",
    "\n",
    "padded_test = np.array([i + [0]*(max_len_test-len(i))\n",
    "                       for i in tokenized_test.values])\n",
    "np.array(padded_test).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De même pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 97)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_app = np.where(padded_app != 0, 1, 0)\n",
    "attention_mask_app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 73)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask_test = np.where(padded_test != 0, 1, 0)\n",
    "attention_mask_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise `np.where()` pour créer une matrice de 0 et de 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfin nous transformer les tokens en tensor pour les passer dans le fameux transformer. Seule la dernière\n",
    "# couche est conservée pour faire la classification.\n",
    "\n",
    "input_ids_app = torch.tensor(padded_app)\n",
    "attention_mask_app = torch.tensor(attention_mask_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attention_mask_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfin nous transformer les tokens en tensor pour les passer dans le fameux transformer. Seule la dernière\n",
    "# couche est conservée pour faire la classification.\n",
    "\n",
    "input_ids_test = torch.tensor(padded_test)\n",
    "attention_mask_test = torch.tensor(attention_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(attention_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states_app = model(\n",
    "        input_ids_app, attention_mask=attention_mask_app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states_test = model(\n",
    "        input_ids_test, attention_mask=attention_mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère ensuite nos encodages avec le modèle BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Entrainer un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "613359710343929857    1\n",
       "611947559444172801    0\n",
       "612264160311803905    0\n",
       "611844583224438784    0\n",
       "615216447787270144    0\n",
       "                     ..\n",
       "614815258092421120    0\n",
       "612216252686299136    0\n",
       "611554358812090368    0\n",
       "613813229735804928    0\n",
       "610829951890120704    0\n",
       "Name: label, Length: 223, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_valid = last_hidden_states_test[0][:, 0, :].numpy()\n",
    "labels_valid = df_test.label\n",
    "labels_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "614484565059596288    0\n",
       "614746522043973632    0\n",
       "614877582664835073    0\n",
       "611932373039644672    0\n",
       "611570404268883969    0\n",
       "                     ..\n",
       "611258135270060033    1\n",
       "612214539468279808    0\n",
       "613678555935973376    0\n",
       "615246897670922240    0\n",
       "613016084371914753    1\n",
       "Name: label, Length: 1258, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = last_hidden_states_app[0][:, 0, :].numpy()\n",
    "labels = df_app.label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    # random_state=39444, # Pour la reproductibilite des analyses/resultats\n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On forme un nouveau jeu de données avec les encodages et les labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Classification des documents à l'aide de la régression logistique multinomiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'multinomial', 'n_jobs': None, 'penalty': 'none', 'random_state': 0, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression(random_state=0, multi_class='multinomial',\n",
    "                            penalty='none', solver='newton-cg').fit(train_features, train_labels)\n",
    "preds = model1.predict(test_features)\n",
    "\n",
    "# print the tunable parameters (They were not tuned in this example, everything kept as default)\n",
    "params = model1.get_params()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Error rate: 0.16\n"
     ]
    }
   ],
   "source": [
    "# Model validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(test_labels, preds)))\n",
    "print('Error rate: {:.2f}'.format(1 - accuracy_score(test_labels, preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Evaluation sur la base de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "preds_valid = model1.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'happy',\n",
       " 1: 'not-relevant',\n",
       " 2: 'angry',\n",
       " 3: 'disgust',\n",
       " 4: 'sad',\n",
       " 5: 'surprise'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction finale avec inverse Tag\n",
    "final_preds = pd.DataFrame(preds_valid)\n",
    "final_preds = final_preds.rename(columns={0: 'preds_Tag'})\n",
    "\n",
    "label_dict_inverse = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict_inverse[index] = possible_label\n",
    "\n",
    "label_dict_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit l'inverse du label_dict pour pouvoir retrouver les labels à partir des valeurs prédites.\n",
    "\n",
    "Une autre façon de faire :\n",
    "\n",
    "```python\n",
    "label_dict_inverse = {v:k for k,v in label_dict.items()}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not-relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        preds_Tag\n",
       "0           happy\n",
       "1           happy\n",
       "2           happy\n",
       "3           happy\n",
       "4    not-relevant\n",
       "..            ...\n",
       "218         happy\n",
       "219         happy\n",
       "220         happy\n",
       "221         happy\n",
       "222         happy\n",
       "\n",
       "[223 rows x 1 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds['preds_Tag'] = final_preds['preds_Tag'].map(label_dict_inverse)\n",
    "\n",
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Error rate: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Model validation\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_valid, preds_valid)))\n",
    "print('Error rate: {:.2f}'.format(\n",
    "    1 - accuracy_score(labels_valid, preds_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       171\n",
      "           1       0.40      0.44      0.42        32\n",
      "           2       0.80      0.44      0.57         9\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.77       223\n",
      "   macro avg       0.46      0.36      0.40       223\n",
      "weighted avg       0.77      0.77      0.77       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Create classification report\n",
    "from sklearn.metrics import classification_report\n",
    "class_report = classification_report(labels_valid, preds_valid)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated probabilities\n",
    "df_results = pd.DataFrame(model1.predict_proba(\n",
    "    features_valid), columns=model1.classes_)\n",
    "valid_values = df_test[['text']]\n",
    "valid_tags = df_test[['category']]\n",
    "# valid_documents = df_test[['id']]\n",
    "valid_values.index = pd.RangeIndex(len(valid_values.index))\n",
    "valid_tags.index = pd.RangeIndex(len(valid_tags.index))\n",
    "# valid_documents.index = pd.RangeIndex(len(valid_documents.index))\n",
    "df_results.index = pd.RangeIndex(len(df_results.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [valid_values, valid_tags, final_preds, df_results.round(decimals=6)]\n",
    "result = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit le dataframe `result` avec les labels prédits et les labels réels. `df_results` contient les probabilités de chaque classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.80      0.44      0.57         9\n",
      "     disgust       0.00      0.00      0.00         1\n",
      "       happy       0.87      0.89      0.88       171\n",
      "not-relevant       0.40      0.44      0.42        32\n",
      "         sad       0.00      0.00      0.00         5\n",
      "    surprise       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.77       223\n",
      "   macro avg       0.46      0.36      0.40       223\n",
      "weighted avg       0.77      0.77      0.77       223\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(valid_tags, final_preds)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`classification_report()` permet de retourner les métriques de classification, ce qui est particulièrement utile pour les problèmes multiclasse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>preds_Tag</th>\n",
       "      <th>happy</th>\n",
       "      <th>not-relevant</th>\n",
       "      <th>angry</th>\n",
       "      <th>disgust</th>\n",
       "      <th>sad</th>\n",
       "      <th>surprise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Over 100 people signed up for 'What's It Worth...</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wonderful experience, hearing Tim Knox’s #obje...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KETTLE'S YARD: ANTIMUSEUM - meet the Archivist...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plus excellent prizes from the @britishmuseum ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feliz cumpleaños,Rubens! Happy birthday,Rubens...</td>\n",
       "      <td>happy</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.999533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Bests museums apps @britishmuseum @uffizidotco...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Well done @britishmuseum - looking forward to ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>@Tate_StIves It was a amazing night , a pleasu...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Enjoyable afternoon @kettlesyard discussing re...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Beguiled, again, by the art of Andrea del Sart...</td>\n",
       "      <td>happy</td>\n",
       "      <td>happy</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>223 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text      category  \\\n",
       "0    Over 100 people signed up for 'What's It Worth...  not-relevant   \n",
       "1    Wonderful experience, hearing Tim Knox’s #obje...         happy   \n",
       "2    KETTLE'S YARD: ANTIMUSEUM - meet the Archivist...         happy   \n",
       "3    Plus excellent prizes from the @britishmuseum ...         happy   \n",
       "4    Feliz cumpleaños,Rubens! Happy birthday,Rubens...         happy   \n",
       "..                                                 ...           ...   \n",
       "218  Bests museums apps @britishmuseum @uffizidotco...         happy   \n",
       "219  Well done @britishmuseum - looking forward to ...         happy   \n",
       "220  @Tate_StIves It was a amazing night , a pleasu...         happy   \n",
       "221  Enjoyable afternoon @kettlesyard discussing re...         happy   \n",
       "222  Beguiled, again, by the art of Andrea del Sart...         happy   \n",
       "\n",
       "        preds_Tag     happy  not-relevant  angry  disgust       sad  surprise  \n",
       "0           happy  0.999246      0.000000    0.0      0.0  0.000754       0.0  \n",
       "1           happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "2           happy  0.999946      0.000054    0.0      0.0  0.000000       0.0  \n",
       "3           happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "4    not-relevant  0.000467      0.999533    0.0      0.0  0.000000       0.0  \n",
       "..            ...       ...           ...    ...      ...       ...       ...  \n",
       "218         happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "219         happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "220         happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "221         happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "222         happy  1.000000      0.000000    0.0      0.0  0.000000       0.0  \n",
       "\n",
       "[223 rows x 9 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.rename(columns=label_dict_inverse)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Tester le Random Forest, SVM, Xgboost, Light GBM, Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89       194\n",
      "           1       0.81      0.36      0.50        36\n",
      "           2       1.00      0.10      0.18        10\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.81       252\n",
      "   macro avg       0.44      0.24      0.26       252\n",
      "weighted avg       0.78      0.81      0.76       252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model2 = RandomForestClassifier(random_state=0, n_jobs=-1).fit(\n",
    "    train_features, train_labels)\n",
    "preds2 = model2.predict(test_features)\n",
    "\n",
    "class_report = classification_report(test_labels, preds2)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       194\n",
      "           1       1.00      0.19      0.33        36\n",
      "           2       0.00      0.00      0.00        10\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.80       252\n",
      "   macro avg       0.30      0.20      0.20       252\n",
      "weighted avg       0.75      0.80      0.73       252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "model3 = SVC(random_state=0).fit(train_features, train_labels)\n",
    "preds3 = model3.predict(test_features)\n",
    "\n",
    "class_report = classification_report(test_labels, preds3)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       194\n",
      "           1       1.00      0.39      0.56        36\n",
      "           2       1.00      0.50      0.67        10\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.85       252\n",
      "   macro avg       0.47      0.31      0.36       252\n",
      "weighted avg       0.82      0.85      0.81       252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Light GBM\n",
    "import lightgbm as lgb\n",
    "model4 = lgb.LGBMClassifier(random_state=0, n_jobs=-1, verbose=-1).fit(\n",
    "    train_features, train_labels)\n",
    "preds4 = model4.predict(test_features)\n",
    "\n",
    "class_report = classification_report(test_labels, preds4)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       194\n",
      "           1       0.70      0.44      0.54        36\n",
      "           2       1.00      0.50      0.67        10\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         5\n",
      "           5       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.83       252\n",
      "   macro avg       0.42      0.32      0.35       252\n",
      "weighted avg       0.79      0.83      0.80       252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\zamax\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(random_state=0, n_jobs=-1)),\n",
    "    ('svr', SVC(random_state=0)),\n",
    "    ('lgbm', lgb.LGBMClassifier(random_state=0, n_jobs=-1, verbose=-1))\n",
    "]\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(random_state=0)).fit(train_features, train_labels)\n",
    "preds5 = clf.predict(test_features)\n",
    "\n",
    "class_report = classification_report(test_labels, preds5)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&uarr; Ici le meilleur modèle est LGBM.\n",
    "\n",
    "De façon générale, on remarque que les 3 dernières classes sont trop peu nombreuses pour être bien prédites et que la seconde et la troisième classe ont un recall trop faible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
